# -*- coding: utf-8 -*-
# app.py
# è¿è¡Œï¼š streamlit run app.py
# åŠŸèƒ½ï¼šä¸Šä¼  .xlsx/.csvï¼›å¡«å†™å¯é€‰çš„ YouTube API Keyï¼›ç‚¹å‡»â€œå¼€å§‹è·å–â€æ‰¹é‡æŠ“å–ï¼Œè®¡ç®—äº’åŠ¨ç‡ï¼Œå­˜å…¥SQLiteï¼›å±•ç¤ºçœ‹æ¿ä¸å¯¼å‡ºCSVã€‚

import streamlit as st
import pandas as pd
from io import StringIO
from fetchers import fetch_metrics
from db import init_db, save_result, Result, SessionLocal
from sqlalchemy import select
import math
from fetchers import fetch_metrics, extract_youtube_id, fetch_youtube_batch_stats
from datetime import datetime


st.set_page_config(page_title="KOL æ•°æ®æŠ“å–çœ‹æ¿", layout="wide")

# åˆå§‹åŒ–æ•°æ®åº“ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™å»ºè¡¨ï¼‰
init_db()

st.title("KOL è·¨å¹³å°æ•°æ®æŠ“å– & çœ‹æ¿ï¼ˆMVPï¼‰")

with st.expander("ä½¿ç”¨è¯´æ˜ï¼ˆç‚¹æ­¤å±•å¼€ï¼‰", expanded=False):
    st.markdown("""
**æ­¥éª¤ï¼š**
1. å°†ä½ æ¯å‘¨çš„KOLé“¾æ¥è¡¨å¯¼å‡ºä¸º `.xlsx` æˆ– `.csv`ï¼Œè‡³å°‘åŒ…å« `platform` å’Œ `url` ä¸¤åˆ—ï¼ˆå¹³å°å€¼ï¼š`youtube` / `instagram` / `tiktok`ï¼‰ã€‚
2. ï¼ˆå¯é€‰ï¼‰å¡«å†™ YouTube API Keyï¼ˆæ›´ç¨³å®šåˆè§„ï¼Œè‹¥ä¸å¡«ä¹Ÿå¯ç”¨ `yt-dlp` ç›´æ¥æŠ“å–ï¼‰ã€‚
3. ä¸Šä¼ æ–‡ä»¶åï¼Œç‚¹å‡» **â€œå¼€å§‹è·å–â€** æŒ‰é’®ï¼Œå³å¯æŠ“å– Views/Likes/Comments å¹¶è®¡ç®—äº’åŠ¨ç‡ã€‚
4. ç»“æœè‡ªåŠ¨å…¥åº“ï¼ˆSQLiteï¼‰ï¼Œä¸‹æ–¹çœ‹æ¿å¯ **ç­›é€‰/å¯¼å‡ºCSV**ã€‚
    """)

# å¯é€‰ï¼šYouTube API Key
youtube_api_key = st.text_input("YouTube API Key", type="password", help="ä¸å¡«ä¹Ÿå¯ä»¥è¿è¡Œï¼Œé»˜è®¤ä½¿ç”¨ yt-dlpã€‚")




uploaded = st.file_uploader("ä¸Šä¼  KOL é“¾æ¥è¡¨ï¼ˆ.xlsx æˆ– .csvï¼‰", type=["xlsx", "csv"])

# ç®€å•çš„è¾“å…¥æ¨¡æ¿ä¸‹è½½
with st.popover("æ²¡æœ‰æ¨¡æ¿ï¼Ÿç‚¹å‡»è·å–CSVæ¨¡æ¿"):
    st.caption("æœ€å°‘åªéœ€è¦ platform, url ä¸¤åˆ—ï¼›å…¶ä»–åˆ—å¯æŒ‰éœ€æ·»åŠ ã€‚")
    example = pd.DataFrame({
        "platform": ["youtube", "instagram", "tiktok"],
        "url": [
            "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
            "https://www.instagram.com/reel/xxxxxx/",
            "https://www.tiktok.com/@user/video/1234567890"
        ],
        "creator": ["Rick", "IG_CREATOR", "TT_CREATOR"],
        "campaign_id": ["W37-Launch", "W37-Launch", "W37-Launch"],
        "posted_at": ["2025-09-10", "2025-09-11", "2025-09-12"],
        "notes": ["ç¤ºä¾‹", "ç¤ºä¾‹", "ç¤ºä¾‹"],
    })
    st.download_button("ä¸‹è½½æ¨¡æ¿ CSV", data=example.to_csv(index=False), file_name="kol_template.csv", mime="text/csv")

# è§£æä¸Šä¼ æ–‡ä»¶ä¸º DataFrame
def read_df(file) -> pd.DataFrame:
    if file is None:
        return pd.DataFrame()
    if file.name.endswith(".csv"):
        return pd.read_csv(file)
    elif file.name.endswith(".xlsx"):
        return pd.read_excel(file)
    else:
        return pd.DataFrame()

df = read_df(uploaded)

if not df.empty:
    st.subheader("ä¸Šä¼ é¢„è§ˆ")
    st.dataframe(df.head(20), use_container_width=True)
    st.info("ç¡®ä¿è‡³å°‘åŒ…å« `platform` ä¸ `url` åˆ—ï¼›å¯é€‰åˆ—ï¼šcreator, campaign_id, posted_at, notesã€‚")

# è¿è¡ŒæŒ‰é’®
run = st.button("â–¶ï¸ å¼€å§‹è·å–", type="primary", disabled=df.empty)

if run and not df.empty:
    st.write("å¼€å§‹æŠ“å–ä¸­ï¼Œè¯·ç¨ç­‰â€¦â€¦ï¼ˆæ¯å‘¨ä¸€æ¬¡ï¼Œé€šå¸¸å‡ åˆ†é’Ÿå†…å®Œæˆï¼‰")
    progress = st.progress(0, text="å‡†å¤‡ä¸­...")
    total = len(df)
    results = []

    # éå†è¡¨æ ¼è¡Œï¼Œé€æ¡æŠ“å–
    for idx, row in df.iterrows():
        platform = str(row.get("platform", "")).strip()
        url = str(row.get("url", "")).strip()

        if not platform or not url:
            # å¿…å¡«æ ¡éªŒ
            continue
 

        try:
            metrics = fetch_metrics(platform, url, youtube_api_key if youtube_api_key else None)
            views = int(metrics.get("views", 0))
            likes = int(metrics.get("likes", 0))
            comments = int(metrics.get("comments", 0))

            # é¢å¤–å–å‡º creator å’Œ posted_at
            creator = metrics.get("creator", "")              # fetch_youtube_batch_stats é‡Œè¿”å›çš„ channelTitle
            published = metrics.get("posted_at", "")          # fetch_youtube_batch_stats é‡Œè¿”å›çš„ publishedAt
            posted_dt = None
            if published:
                try:
                    posted_dt = datetime.fromisoformat(published.replace("Z", "+00:00"))
                except Exception:
                    posted_dt = None

            engagement_rate = round(((likes + comments) / views * 100.0), 2) if views > 0 else 0.0

            row_dict = {
                "platform": platform.lower(),
                "url": url,
                "creator": creator,          # æ¥è‡ª APIï¼Œä¸å†ä» CSV è¯»
                "posted_at": posted_dt,      # è½¬æˆ datetime å­˜æ•°æ®åº“
                "views": views,
                "likes": likes,
                "comments": comments,
                "engagement_rate": engagement_rate,
            }
            save_result(row_dict)
            results.append(row_dict)

        except Exception as e:
            # æŸä¸€æ¡å¤±è´¥ä¸å½±å“æ•´ä½“
            st.warning(f"æŠ“å–å¤±è´¥ï¼ˆç¬¬ {idx+1} è¡Œï¼‰ï¼š{url}ï¼ŒåŸå› ï¼š{e}")

        progress.progress(min((idx + 1) / total, 1.0), text=f"è¿›åº¦ï¼š{idx+1}/{total}")

    st.success(f"æŠ“å–å®Œæˆï¼æˆåŠŸå†™å…¥ {len(results)} æ¡è®°å½•ã€‚")

st.divider()
st.subheader("ğŸ“Š å†å²æŠ“å–ç»“æœçœ‹æ¿ï¼ˆæ¥è‡ª SQLiteï¼‰")

# ç®€å•ç­›é€‰
with st.container():
    with SessionLocal() as s:
        stmt = select(Result).order_by(Result.id.asc())
        rows = s.execute(stmt).scalars().all()
        

    if rows:
        import pandas as pd
        data = pd.DataFrame([{
            "id": r.id,
            "platform": r.platform,
            "url": r.url,
            "creator": r.creator,
            "posted_at": r.posted_at,
            "views": r.views,
            "likes": r.likes,
            "comments": r.comments,
            "engagement_rate(%)": round(r.engagement_rate, 2),
            "fetched_at(UTC)": r.fetched_at,
        } for r in rows])
            # è¯»åº“åå±•ç¤ºå‰
        data = data.sort_values("id", ascending=True)      # id å‡åº
        st.dataframe(data.set_index("id"), use_container_width=True, height=420)
            
     # â€”â€” å®‰å…¨ç­›é€‰åŒºï¼ˆæ ¹æ®å®é™…åˆ—åŠ¨æ€æ¸²æŸ“ï¼‰â€”â€”
    cols = st.columns(3)

    # å¹³å°ç­›é€‰ï¼ˆä¸€èˆ¬éƒ½ä¼šæœ‰ï¼‰
    with cols[0]:
        platform_filter = []
        if "platform" in data.columns:
            platform_filter = st.multiselect(
                "å¹³å°ç­›é€‰",
                options=sorted(data["platform"].dropna().unique().tolist())
            )

    # æ´»åŠ¨IDç­›é€‰ï¼šåˆ—ä¸å­˜åœ¨å°±ä¸æ¸²æŸ“
    with cols[1]:
        campaign_filter = []
        if "campaign_id" in data.columns:
            campaign_filter = st.multiselect(
                "æ´»åŠ¨IDç­›é€‰",
                options=sorted(data["campaign_id"].dropna().unique().tolist())
            )

    # KOL/ä½œè€…ç­›é€‰ï¼šåˆ—ä¸å­˜åœ¨å°±ä¸æ¸²æŸ“
    with cols[2]:
        creator_filter = []
        if "creator" in data.columns:
            creator_filter = st.multiselect(
                "KOLç­›é€‰",
                options=sorted(data["creator"].dropna().unique().tolist())
            )

    # è¿‡æ»¤é€»è¾‘ï¼šåªæœ‰å½“åˆ—å­˜åœ¨ä¸”ç”¨æˆ·é€‰æ‹©äº†å€¼æ—¶æ‰åº”ç”¨
    filtered = data.copy()
    if platform_filter and "platform" in filtered.columns:
        filtered = filtered[filtered["platform"].isin(platform_filter)]
    if campaign_filter and "campaign_id" in filtered.columns:
        filtered = filtered[filtered["campaign_id"].isin(campaign_filter)]
    if creator_filter and "creator" in filtered.columns:
        filtered = filtered[filtered["creator"].isin(creator_filter)]

    st.dataframe(filtered.set_index("id"), use_container_width=True, height=420)

    st.download_button(
        "â¬‡ï¸ å¯¼å‡ºå½“å‰ç­›é€‰ç»“æœï¼ˆCSVï¼‰",
        data=filtered.to_csv(index=False),
        file_name="kol_results_filtered.csv",
        mime="text/csv"
    )





if run and not df.empty:
    st.write("å¼€å§‹æŠ“å–ä¸­ï¼Œè¯·ç¨ç­‰â€¦â€¦ï¼ˆæ¯å‘¨ä¸€æ¬¡ï¼Œé€šå¸¸å‡ åˆ†é’Ÿå†…å®Œæˆï¼‰")
    progress = st.progress(0, text="å‡†å¤‡ä¸­...")
    total = len(df)
    results = []
    errors = []

    # æ ‡å‡†åŒ–åˆ—å
    df.columns = [str(c).strip().lower() for c in df.columns]

    # è‡ªåŠ¨æ¨æ–­ url åˆ—ï¼ˆå¦‚ç”¨æˆ·æ²¡å‘½åä¸º urlï¼‰
    if "url" not in df.columns:
        import re as _re
        for c in df.columns:
            s = df[c].astype(str)
            if s.str.contains(r"^https?://", flags=_re.IGNORECASE, na=False).any():
                df = df.rename(columns={c: "url"})
                break

    # è‡ªåŠ¨æ¨æ–­ platform
    def infer_platform(u: str) -> str:
        ul = (u or "").lower()
        if "youtube.com" in ul or "youtu.be" in ul:
            return "youtube"
        if "instagram.com" in ul:
            return "instagram"
        if "tiktok.com" in ul:
            return "tiktok"
        return ""

    if "platform" not in df.columns:
        df["platform"] = df["url"].apply(infer_platform)

    # --- åˆ†å¹³å°å¤„ç† ---
    df = df[["platform", "url", "creator", "campaign_id", "posted_at", "notes"] if "creator" in df.columns else ["platform","url"]].copy()

    # 1) YouTube æ‰¹é‡ï¼ˆéœ€è¦ API Keyï¼‰
    yt_rows = df[df["platform"].str.lower() == "youtube"]
    if not yt_rows.empty:
        if not youtube_api_key:
            errors.append("YouTube æŠ“å–å·²ç¦ç”¨ï¼šæœªæä¾› API Keyã€‚")
        else:
            # æ”¶é›†æ‰€æœ‰ videoId
            yt_rows = yt_rows.copy()
            yt_rows["video_id"] = yt_rows["url"].apply(extract_youtube_id)
            yt_rows = yt_rows[yt_rows["video_id"].notna()]
            vids = yt_rows["video_id"].tolist()

            # åˆ†å—è¯·æ±‚ï¼ˆ<= 50ï¼‰
            chunk_size = 50
            stats_map = {}
            for i in range(0, len(vids), chunk_size):
                chunk = vids[i:i+chunk_size]
                try:
                    part = fetch_youtube_batch_stats(chunk, youtube_api_key)
                    stats_map.update(part)
                except Exception as e:
                    errors.append(f"YouTube æ‰¹é‡å¤±è´¥ï¼ˆ{i}-{i+len(chunk)-1}ï¼‰ï¼š{e}")

                progress.progress(min((i + chunk_size) / max(len(vids),1), 1.0), text=f"YouTube æ‰¹é‡ï¼š{min(i+chunk_size,len(vids))}/{len(vids)}")

            # å†™å…¥ç»“æœ
            for _, r in yt_rows.iterrows():
                s = stats_map.get(r["video_id"], {"views":0,"likes":0,"comments":0})
                views = int(s.get("views",0)); likes = int(s.get("likes",0)); comments = int(s.get("comments",0))
                er = round(((likes+comments)/views*100.0), 2) if views>0 else 0.0
                results.append({
                    "platform": "youtube",
                    "url": r["url"],
                    "creator": r.get("creator"),
                    "campaign_id": r.get("campaign_id"),
                    "posted_at": r.get("posted_at"),
                    "views": views,
                    "likes": likes,
                    "comments": comments,
                    "engagement_rate": er,
                })

    # 2) å…¶ä»–å¹³å°ï¼šä»ä½¿ç”¨ yt-dlp å•æ¡ï¼ˆæ•°é‡å°‘å½±å“ä¸å¤§ï¼‰
    other_rows = df[df["platform"].str.lower().isin(["instagram","tiktok"])]
    processed = 0
    for idx, row in other_rows.iterrows():
        url = str(row.get("url","") or "").strip()
        platform = str(row.get("platform","") or "").strip().lower()
        if not url or not platform:
            errors.append(f"ç¬¬ {idx+1} è¡Œç¼ºå°‘ platform/urlï¼Œå·²è·³è¿‡ã€‚"); continue
        try:
            metrics = fetch_metrics(platform, url, None)
            views = int(metrics.get("views", 0))
            likes = int(metrics.get("likes", 0))
            comments = int(metrics.get("comments", 0))
            er = round(((likes+comments)/views*100.0), 2) if views>0 else 0.0
            results.append({
                "platform": platform,
                "url": url,
                "creator": row.get("creator"),
                "campaign_id": row.get("campaign_id"),
                "posted_at": row.get("posted_at"),
                "views": views, "likes": likes, "comments": comments,
                "engagement_rate": er,
            })
        except Exception as e:
            errors.append(f"æŠ“å–å¤±è´¥ï¼ˆç¬¬ {idx+1} è¡Œï¼‰ï¼š{url}ï¼ŒåŸå› ï¼š{e}")
        processed += 1
        # é€‚åº¦æ›´æ–°è¿›åº¦
        if processed % 5 == 0 or processed == len(other_rows):
            progress.progress(1.0, text=f"å…¶ä»–å¹³å°ï¼š{processed}/{len(other_rows)}")

    # å†™åº“ï¼ˆæ‰¹é‡ä¸€æ¬¡ï¼‰
    from db import save_result, SessionLocal
    if results:
        from sqlalchemy.orm import Session
        with SessionLocal() as s:
            from db import Result
            s.bulk_insert_mappings(Result, results)
            s.commit()
        st.success(f"æŠ“å–å®Œæˆï¼æˆåŠŸå†™å…¥ {len(results)} æ¡è®°å½•ã€‚")
    else:
        st.warning("æœªå†™å…¥è®°å½•ã€‚")

    if errors:
        st.warning("ä»¥ä¸‹è®°å½•æœªå†™å…¥/å¤±è´¥ï¼š\n" + "\n".join(errors))